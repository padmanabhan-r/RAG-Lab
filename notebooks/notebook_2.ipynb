{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b02e9b0",
   "metadata": {},
   "source": [
    "# Imports, Set up Asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1dd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6dbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import qdrant_client\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578eb47",
   "metadata": {},
   "source": [
    "# Connecting to Qdrant\n",
    "This section establishes a connection to the Qdrant vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed658fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "collection_name=\"chat_with_docs_v2\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e8b6e",
   "metadata": {},
   "source": [
    "# Instrumentation Setup\n",
    "This section sets up instrumentation for tracing and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd705230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register()\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a8090",
   "metadata": {},
   "source": [
    "# Define the LLM, the embedding model and re-ranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22f549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747497762.391316   19758 chttp2_transport.cc:1201] ipv6:%5B::1%5D:4317: Got goaway [11] err=UNAVAILABLE:GOAWAY received; Error code: 11; Debug Text: ping_timeout {created_time:\"2025-05-17T21:32:42.388851021+05:30\", http2_error:11, grpc_status:14}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello! I am doing well, thank you for asking. I'm ready and eager to assist you. How can I help you today?\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Example for Groq (commented out for now)\n",
    "# from llama_index.llms.groq import Groq\n",
    "# llm = Groq(model=\"gemma2-9b-it\", request_timeout=120.0)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from google.auth import default\n",
    "from llama_index.llms.vertex import Vertex\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.base.llms.types import ChatMessage\n",
    "\n",
    "# Suppress Vertex deprecation warnings (switch to GoogleGenAI soon)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Google Cloud default credentials\n",
    "credentials, _ = default()\n",
    "\n",
    "# Initialize Vertex LLM\n",
    "llm = Vertex(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    "    credentials=credentials,\n",
    "    project=os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\"),\n",
    "    location=os.getenv(\"GOOGLE_CLOUD_PROJECT_REGION\"),\n",
    ")\n",
    "llm._chat_client._response_validation = False\n",
    "# Set as default LLM for LlamaIndex\n",
    "Settings.llm = llm\n",
    "\n",
    "# Example chat call\n",
    "response = llm.chat([\n",
    "    ChatMessage(role=\"user\", content=\"Hello there Gemini! How are you doing today?\")\n",
    "])\n",
    "print(response)\n",
    "\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "rerank = SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\", top_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b2044",
   "metadata": {},
   "source": [
    "# Read the documents\n",
    "This section loads documents from the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4363deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "input_dir_path = './paul_graham'\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".txt\"],\n",
    "            recursive=True\n",
    "        )\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1b07a",
   "metadata": {},
   "source": [
    "# Checking Loaded Documents\n",
    "This section checks the type and number of loaded documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4096dacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs), len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e75700",
   "metadata": {},
   "source": [
    "# Set up the Qdrant vector database\n",
    "This section defines a function to create a vector store index using Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac428e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = qdrant_client.QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client,\n",
    "                                 collection_name=\"document_chat\")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465d3c2",
   "metadata": {},
   "source": [
    "# Define the query engine and prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ec3757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747495727.964148   19758 chttp2_transport.cc:1201] ipv6:%5B::1%5D:4317: Got goaway [11] err=UNAVAILABLE:GOAWAY received; Error code: 11; Debug Text: ping_timeout {created_time:\"2025-05-17T20:58:47.961899007+05:30\", http2_error:11, grpc_status:14}\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=4,\n",
    "                                     node_postprocessors=[rerank])\n",
    "\n",
    "template = \"\"\"Context information is below.\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Given the context information above I want you to think\n",
    "              step by step to answer the query in a crisp manner. Incase \n",
    "              you don't know the answer say 'I don't know!'.\n",
    "              \n",
    "              Query: {query_str}\n",
    "              \n",
    "              Answer:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30005276",
   "metadata": {},
   "source": [
    "# Query the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0b3e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a breakdown of how funding startups in batches contributed to Y Combinator's success and the startups' growth:\n",
       "\n",
       "1.  **Convenience for YC:** Batch funding allowed YC to efficiently support multiple startups simultaneously. They could implement initiatives and assistance programs for a large group, making their efforts more impactful.\n",
       "\n",
       "2.  **Reduced Isolation for Startups:** Being part of a batch provided startups with a network of peers facing similar challenges. This fostered collaboration, knowledge sharing, and mutual support.\n",
       "\n",
       "3.  **Community Building:** As YC grew, the alumni network became a strong community, dedicated to helping current batches and each other. This created a valuable resource for mentorship and guidance.\n",
       "\n",
       "4.  **Internal Customer Base:** Startups within a batch often became each other's initial customers, creating a mini-economy within YC. This helped startups gain traction and early revenue.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"\"\"How did the structure of funding startups \n",
    "                                 in batches contribute to the success and \n",
    "                                 growth of the Y Combinator program and the\n",
    "                                 startups involved?\"\"\")\n",
    "                                 \n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec42da3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8069fa0",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72ac1c",
   "metadata": {},
   "source": [
    "# RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc70604",
   "metadata": {},
   "source": [
    "### Load the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1d93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader(\"./paul_graham/\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "documents = loader.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c32b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'schema', 'document', 'Document'],\n",
       " 'kwargs': {'metadata': {'source': 'paul_graham/how_to_do_great_things.txt'},\n",
       "  'page_content': 'How to Do Great Work\\n\\nJuly 2023\\n\\nIf you collected lists of techniques for doing great work in a lot of different fields, what would the intersection look like? I decided to find out by making it.\\n\\nPartly my goal was to create a guide that could be used by someone working in any field. But I was also curious about the shape of the intersection. And one thing this exercise shows is that it does have a definite shape; it\\'s not just a point labelled \"work hard.\"\\n\\nThe following recipe assumes you\\'re very ambitious.\\n\\nThe first step is to decide what to work on. The work you choose needs to have three qualities: it has to be something you have a natural aptitude for, that you have a deep interest in, and that offers scope to do great work.\\n\\nIn practice you don\\'t have to worry much about the third criterion. Ambitious people are if anything already too conservative about it. So all you need to do is find something you have an aptitude for and great interest in. [1]',\n",
       "  'type': 'Document'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb49656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "generator_llm = Vertex(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    "    credentials=credentials,\n",
    "    project=os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\"),\n",
    "    location=os.getenv(\"GOOGLE_CLOUD_PROJECT_REGION\"),\n",
    ")\n",
    "\n",
    "critic_llm =  Vertex(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    temperature=0.7,\n",
    "    credentials=credentials,\n",
    "    project=os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\"),\n",
    "    location=os.getenv(\"GOOGLE_CLOUD_PROJECT_REGION\"),\n",
    ")\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914195c0",
   "metadata": {},
   "source": [
    "Note: You might not be able to run the below code on your local machine. If at least a progress bar appears, you know you have done it right. For the time being, you can utilize this CSV file which I will share below, which has been generated from my run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=ollama_emb\n",
    ")\n",
    "\n",
    "distribution = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "testset = generator.generate_with_langchain_docs(documents,\n",
    "                                                 test_size=10,\n",
    "                                                 distributions=distribution,\n",
    "                                                 raise_exceptions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0de6a",
   "metadata": {},
   "source": [
    "## Evaluate the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6dd4c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How did the shift to publishing on the web cha...</td>\n",
       "      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n",
       "      <td>The shift to publishing on the web changed the...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How does criticizing a project as a \"toy\" rese...</td>\n",
       "      <td>[\"[9] You can't usually get paid for doing exa...</td>\n",
       "      <td>Criticizing a project as a 'toy' is similar to...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How did the structure of funding startups in b...</td>\n",
       "      <td>['The deal for startups was based on a combina...</td>\n",
       "      <td>Funding startups in batches allowed for conven...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>How can exploring different topics help in gen...</td>\n",
       "      <td>[\"Talking or writing about the things you're i...</td>\n",
       "      <td>Exploring different topics can help in generat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How does focusing consistently on something yo...</td>\n",
       "      <td>[\"The way to beat it is to stop occasionally a...</td>\n",
       "      <td>Great work happens by focusing consistently on...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>What are the benefits of starting with somethi...</td>\n",
       "      <td>['Don\\'t try to cram too much new stuff into a...</td>\n",
       "      <td>Starting with something small and evolving it ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>How does being earnest impact the process of d...</td>\n",
       "      <td>[\"There may be some jobs where it's an advanta...</td>\n",
       "      <td>Being earnest is crucial for the process of di...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>What were the initial perceptions of online es...</td>\n",
       "      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n",
       "      <td>Socially, during the early days of online cont...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What is the importance of avoiding affectation...</td>\n",
       "      <td>[\"One way to aim high is to try to make someth...</td>\n",
       "      <td>Avoiding affectation and focusing on earnestne...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>How can being promiscuously curious and starti...</td>\n",
       "      <td>[\"The best questions grow in the answering. Yo...</td>\n",
       "      <td>Being promiscuously curious and starting lots ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>How is the ability to generate true and new id...</td>\n",
       "      <td>['True by itself is not enough, of course. Gre...</td>\n",
       "      <td>The ability to generate true and new ideas is ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>What technical and non-technical challenges di...</td>\n",
       "      <td>[\"Now they are, though. Now you could continue...</td>\n",
       "      <td>The author faced technical challenges in defin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>How did Paul Graham transition from building a...</td>\n",
       "      <td>[\"If I wanted to get rich, here was the next t...</td>\n",
       "      <td>After facing challenges with the idea of putti...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>What was the initial focus of Y Combinator bef...</td>\n",
       "      <td>[\"There are multiple components to Y Combinato...</td>\n",
       "      <td>The initial focus of Y Combinator was to be an...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>What pattern has the author, specifically Paul...</td>\n",
       "      <td>[\"One of the most conspicuous patterns I've no...</td>\n",
       "      <td>Paul Graham has noticed a pattern in his life ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>How does being curious increase the likelihood...</td>\n",
       "      <td>[\"[4] Finding something to work on is not simp...</td>\n",
       "      <td>Curious people are more likely to do great wor...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>How does clearing away nonsensical or irreleva...</td>\n",
       "      <td>[\"One of the most valuable kinds of knowledge ...</td>\n",
       "      <td>Clearing away nonsensical or irrelevant though...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>How did microcomputers revolutionize the way i...</td>\n",
       "      <td>['With microcomputers, everything changed. Now...</td>\n",
       "      <td>Microcomputers revolutionized the way individu...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>What was the funding model for Y Combinator, a...</td>\n",
       "      <td>['YC was not organized as a fund. It was cheap...</td>\n",
       "      <td>YC was not organized as a fund and was funded ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>How did the graphical user interface impact th...</td>\n",
       "      <td>[\"She liked to paint on big, square canvases, ...</td>\n",
       "      <td>The graphical user interface greatly increased...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>What led the author to consider building a sub...</td>\n",
       "      <td>[\"I started working on the application builder...</td>\n",
       "      <td>The author realized halfway through the summer...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>How can ambitious people guard themselves agai...</td>\n",
       "      <td>['One of the biggest mistakes ambitious people...</td>\n",
       "      <td>One way for ambitious people to guard themselv...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>What challenges does an ambitious person face ...</td>\n",
       "      <td>[\"The educational systems in most countries pr...</td>\n",
       "      <td>An ambitious person within the educational sys...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>How does inexperience in young individuals inf...</td>\n",
       "      <td>[\"Planning per se isn't good. It's sometimes n...</td>\n",
       "      <td>Inexperience in young individuals tends to mak...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>How did the transition to online publishing im...</td>\n",
       "      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n",
       "      <td>The transition to online publishing impacted t...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Which era involved editors as gatekeepers for ...</td>\n",
       "      <td>[\"Wow, I thought, there's an audience. If I wr...</td>\n",
       "      <td>The print era involved editors as gatekeepers ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>How does focusing on your interests in digital...</td>\n",
       "      <td>[\"When in doubt, optimize for interestingness....</td>\n",
       "      <td>Focusing on your interests in digital product ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>What's the role of questions in creativity and...</td>\n",
       "      <td>[\"Don't divide your attention evenly between m...</td>\n",
       "      <td>Curiosity and originality are closely related....</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>What advantageous trait helps in fast-changing...</td>\n",
       "      <td>[\"[10] This was the first instance of what is ...</td>\n",
       "      <td>Independent-minded individuals have an advanta...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>By honing in on our passions, how does concent...</td>\n",
       "      <td>[\"The way to beat it is to stop occasionally a...</td>\n",
       "      <td>By focusing consistently on something we're ge...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Why is intellectual honesty crucial for achiev...</td>\n",
       "      <td>[\"There may be some jobs where it's an advanta...</td>\n",
       "      <td>Intellectual honesty is crucial for achieving ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>What misconceptions devalue questioning in exp...</td>\n",
       "      <td>[\"Originality in choosing problems seems to ma...</td>\n",
       "      <td>One of the biggest misconceptions about new id...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>What strategy was used to attract users to the...</td>\n",
       "      <td>[\"[8] Most software you can launch as soon as ...</td>\n",
       "      <td>Before launching publicly, the company launche...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>How does leadership style impact tech company ...</td>\n",
       "      <td>[\"I learned some useful things at Interleaf, t...</td>\n",
       "      <td>Leadership style impacts tech company success ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>How does \"A Mathematician's Apology\" by G.H. H...</td>\n",
       "      <td>['Notes\\n\\n[1] I don\\'t think you could give a...</td>\n",
       "      <td>A Mathematician's Apology by G.H. Hardy emphas...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>How can diverse interests boost creativity and...</td>\n",
       "      <td>[\"What should you do if you're young and ambit...</td>\n",
       "      <td>Diverse interests can boost creativity and ada...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>How does the certainty level of conventional a...</td>\n",
       "      <td>['[20] The connection between originality and ...</td>\n",
       "      <td>Conventional-minded individuals, who are usual...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>How did the 1990s computing surge affect high-...</td>\n",
       "      <td>[\"[5] Interleaf was one of many companies that...</td>\n",
       "      <td>In the 1990s, the exponential growth in the po...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>How does curiosity, reading, and boldness cont...</td>\n",
       "      <td>[\"What should you do if you're young and ambit...</td>\n",
       "      <td>Curiosity, reading, and boldness contribute to...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>How to balance authenticity in acting with the...</td>\n",
       "      <td>[\"[9] You can't usually get paid for doing exa...</td>\n",
       "      <td>Achieving authenticity in acting while benefit...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Why does genuine interest matter for work qual...</td>\n",
       "      <td>[\"The way to beat it is to stop occasionally a...</td>\n",
       "      <td>Genuine interest matters for work quality and ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>How does problem selection impact expertise an...</td>\n",
       "      <td>[\"Unanswered questions can be uncomfortable th...</td>\n",
       "      <td>The key to expertise and innovation lies in th...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>How to maintain integrity and quality in acade...</td>\n",
       "      <td>[\"The core of being earnest is being intellect...</td>\n",
       "      <td>One way to maintain integrity and quality in a...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>How does careful observation impact uncovering...</td>\n",
       "      <td>[\"The most subtle advantage of youth, or more ...</td>\n",
       "      <td>Careful observation plays a crucial role in un...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>How do initial perceptions of complex problems...</td>\n",
       "      <td>['Mathematical elegance may sound like a mere ...</td>\n",
       "      <td>Initial perceptions of complex problems often ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/how_to_do_great_thing...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>How do marketing transitions in finance to sta...</td>\n",
       "      <td>['Jessica was in charge of marketing at a Bost...</td>\n",
       "      <td>The transition from marketing in finance to st...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>What was Viaweb's fee for a small store in Jan...</td>\n",
       "      <td>[\"There were a lot of startups making ecommerc...</td>\n",
       "      <td>Viaweb's fee for a small store in January 1996...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'paul_graham/what_i_worked_on.txt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                           question  \\\n",
       "0            0  How did the shift to publishing on the web cha...   \n",
       "1            1  How does criticizing a project as a \"toy\" rese...   \n",
       "2            2  How did the structure of funding startups in b...   \n",
       "3            3  How can exploring different topics help in gen...   \n",
       "4            4  How does focusing consistently on something yo...   \n",
       "5            5  What are the benefits of starting with somethi...   \n",
       "6            6  How does being earnest impact the process of d...   \n",
       "7            7  What were the initial perceptions of online es...   \n",
       "8            8  What is the importance of avoiding affectation...   \n",
       "9            9  How can being promiscuously curious and starti...   \n",
       "10          10  How is the ability to generate true and new id...   \n",
       "11          11  What technical and non-technical challenges di...   \n",
       "12          12  How did Paul Graham transition from building a...   \n",
       "13          13  What was the initial focus of Y Combinator bef...   \n",
       "14          14  What pattern has the author, specifically Paul...   \n",
       "15          15  How does being curious increase the likelihood...   \n",
       "16          16  How does clearing away nonsensical or irreleva...   \n",
       "17          17  How did microcomputers revolutionize the way i...   \n",
       "18          18  What was the funding model for Y Combinator, a...   \n",
       "19          19  How did the graphical user interface impact th...   \n",
       "20          20  What led the author to consider building a sub...   \n",
       "21          21  How can ambitious people guard themselves agai...   \n",
       "22          22  What challenges does an ambitious person face ...   \n",
       "23          23  How does inexperience in young individuals inf...   \n",
       "24          24  How did the transition to online publishing im...   \n",
       "25          25  Which era involved editors as gatekeepers for ...   \n",
       "26          26  How does focusing on your interests in digital...   \n",
       "27          27  What's the role of questions in creativity and...   \n",
       "28          28  What advantageous trait helps in fast-changing...   \n",
       "29          29  By honing in on our passions, how does concent...   \n",
       "30          30  Why is intellectual honesty crucial for achiev...   \n",
       "31          31  What misconceptions devalue questioning in exp...   \n",
       "32          32  What strategy was used to attract users to the...   \n",
       "33          33  How does leadership style impact tech company ...   \n",
       "34          34  How does \"A Mathematician's Apology\" by G.H. H...   \n",
       "35          35  How can diverse interests boost creativity and...   \n",
       "36          36  How does the certainty level of conventional a...   \n",
       "37          37  How did the 1990s computing surge affect high-...   \n",
       "38          38  How does curiosity, reading, and boldness cont...   \n",
       "39          39  How to balance authenticity in acting with the...   \n",
       "40          40  Why does genuine interest matter for work qual...   \n",
       "41          41  How does problem selection impact expertise an...   \n",
       "42          42  How to maintain integrity and quality in acade...   \n",
       "43          43  How does careful observation impact uncovering...   \n",
       "44          44  How do initial perceptions of complex problems...   \n",
       "45          45  How do marketing transitions in finance to sta...   \n",
       "46          46  What was Viaweb's fee for a small store in Jan...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [\"Wow, I thought, there's an audience. If I wr...   \n",
       "1   [\"[9] You can't usually get paid for doing exa...   \n",
       "2   ['The deal for startups was based on a combina...   \n",
       "3   [\"Talking or writing about the things you're i...   \n",
       "4   [\"The way to beat it is to stop occasionally a...   \n",
       "5   ['Don\\'t try to cram too much new stuff into a...   \n",
       "6   [\"There may be some jobs where it's an advanta...   \n",
       "7   [\"Wow, I thought, there's an audience. If I wr...   \n",
       "8   [\"One way to aim high is to try to make someth...   \n",
       "9   [\"The best questions grow in the answering. Yo...   \n",
       "10  ['True by itself is not enough, of course. Gre...   \n",
       "11  [\"Now they are, though. Now you could continue...   \n",
       "12  [\"If I wanted to get rich, here was the next t...   \n",
       "13  [\"There are multiple components to Y Combinato...   \n",
       "14  [\"One of the most conspicuous patterns I've no...   \n",
       "15  [\"[4] Finding something to work on is not simp...   \n",
       "16  [\"One of the most valuable kinds of knowledge ...   \n",
       "17  ['With microcomputers, everything changed. Now...   \n",
       "18  ['YC was not organized as a fund. It was cheap...   \n",
       "19  [\"She liked to paint on big, square canvases, ...   \n",
       "20  [\"I started working on the application builder...   \n",
       "21  ['One of the biggest mistakes ambitious people...   \n",
       "22  [\"The educational systems in most countries pr...   \n",
       "23  [\"Planning per se isn't good. It's sometimes n...   \n",
       "24  [\"Wow, I thought, there's an audience. If I wr...   \n",
       "25  [\"Wow, I thought, there's an audience. If I wr...   \n",
       "26  [\"When in doubt, optimize for interestingness....   \n",
       "27  [\"Don't divide your attention evenly between m...   \n",
       "28  [\"[10] This was the first instance of what is ...   \n",
       "29  [\"The way to beat it is to stop occasionally a...   \n",
       "30  [\"There may be some jobs where it's an advanta...   \n",
       "31  [\"Originality in choosing problems seems to ma...   \n",
       "32  [\"[8] Most software you can launch as soon as ...   \n",
       "33  [\"I learned some useful things at Interleaf, t...   \n",
       "34  ['Notes\\n\\n[1] I don\\'t think you could give a...   \n",
       "35  [\"What should you do if you're young and ambit...   \n",
       "36  ['[20] The connection between originality and ...   \n",
       "37  [\"[5] Interleaf was one of many companies that...   \n",
       "38  [\"What should you do if you're young and ambit...   \n",
       "39  [\"[9] You can't usually get paid for doing exa...   \n",
       "40  [\"The way to beat it is to stop occasionally a...   \n",
       "41  [\"Unanswered questions can be uncomfortable th...   \n",
       "42  [\"The core of being earnest is being intellect...   \n",
       "43  [\"The most subtle advantage of youth, or more ...   \n",
       "44  ['Mathematical elegance may sound like a mere ...   \n",
       "45  ['Jessica was in charge of marketing at a Bost...   \n",
       "46  [\"There were a lot of startups making ecommerc...   \n",
       "\n",
       "                                         ground_truth evolution_type  \\\n",
       "0   The shift to publishing on the web changed the...         simple   \n",
       "1   Criticizing a project as a 'toy' is similar to...         simple   \n",
       "2   Funding startups in batches allowed for conven...         simple   \n",
       "3   Exploring different topics can help in generat...         simple   \n",
       "4   Great work happens by focusing consistently on...         simple   \n",
       "5   Starting with something small and evolving it ...         simple   \n",
       "6   Being earnest is crucial for the process of di...         simple   \n",
       "7   Socially, during the early days of online cont...         simple   \n",
       "8   Avoiding affectation and focusing on earnestne...         simple   \n",
       "9   Being promiscuously curious and starting lots ...         simple   \n",
       "10  The ability to generate true and new ideas is ...         simple   \n",
       "11  The author faced technical challenges in defin...         simple   \n",
       "12  After facing challenges with the idea of putti...         simple   \n",
       "13  The initial focus of Y Combinator was to be an...         simple   \n",
       "14  Paul Graham has noticed a pattern in his life ...         simple   \n",
       "15  Curious people are more likely to do great wor...         simple   \n",
       "16  Clearing away nonsensical or irrelevant though...         simple   \n",
       "17  Microcomputers revolutionized the way individu...         simple   \n",
       "18  YC was not organized as a fund and was funded ...         simple   \n",
       "19  The graphical user interface greatly increased...         simple   \n",
       "20  The author realized halfway through the summer...         simple   \n",
       "21  One way for ambitious people to guard themselv...         simple   \n",
       "22  An ambitious person within the educational sys...         simple   \n",
       "23  Inexperience in young individuals tends to mak...         simple   \n",
       "24  The transition to online publishing impacted t...         simple   \n",
       "25  The print era involved editors as gatekeepers ...      reasoning   \n",
       "26  Focusing on your interests in digital product ...      reasoning   \n",
       "27  Curiosity and originality are closely related....      reasoning   \n",
       "28  Independent-minded individuals have an advanta...      reasoning   \n",
       "29  By focusing consistently on something we're ge...      reasoning   \n",
       "30  Intellectual honesty is crucial for achieving ...      reasoning   \n",
       "31  One of the biggest misconceptions about new id...      reasoning   \n",
       "32  Before launching publicly, the company launche...      reasoning   \n",
       "33  Leadership style impacts tech company success ...      reasoning   \n",
       "34  A Mathematician's Apology by G.H. Hardy emphas...      reasoning   \n",
       "35  Diverse interests can boost creativity and ada...      reasoning   \n",
       "36  Conventional-minded individuals, who are usual...  multi_context   \n",
       "37  In the 1990s, the exponential growth in the po...  multi_context   \n",
       "38  Curiosity, reading, and boldness contribute to...  multi_context   \n",
       "39  Achieving authenticity in acting while benefit...  multi_context   \n",
       "40  Genuine interest matters for work quality and ...  multi_context   \n",
       "41  The key to expertise and innovation lies in th...  multi_context   \n",
       "42  One way to maintain integrity and quality in a...  multi_context   \n",
       "43  Careful observation plays a crucial role in un...  multi_context   \n",
       "44  Initial perceptions of complex problems often ...  multi_context   \n",
       "45  The transition from marketing in finance to st...  multi_context   \n",
       "46  Viaweb's fee for a small store in January 1996...  multi_context   \n",
       "\n",
       "                                             metadata  episode_done  \n",
       "0   [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "1   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "2   [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "3   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "4   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "5   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "6   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "7   [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "8   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "9   [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "10  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "11  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "12  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "13  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "14  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "15  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "16  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "17  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "18  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "19  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "20  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "21  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "22  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "23  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "24  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "25  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "26  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "27  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "28  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "29  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "30  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "31  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "32  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "33  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "34  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "35  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "36  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "37  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "38  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "39  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "40  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "41  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "42  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "43  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "44  [{'source': 'paul_graham/how_to_do_great_thing...          True  \n",
       "45  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  \n",
       "46  [{'source': 'paul_graham/what_i_worked_on.txt'...          True  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('eval/test_data_paul_graham.csv').dropna()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38d54f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query_engine, question):\n",
    "    response = query_engine.query(question)\n",
    "    return {\n",
    "        \"answer\": response.response,\n",
    "        \"contexts\": [c.node.get_content() for c in response.source_nodes],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29f7faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd7558a932c4c26b52941f84191720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747497441.604074   19758 chttp2_transport.cc:1201] ipv6:%5B::1%5D:4317: Got goaway [11] err=UNAVAILABLE:GOAWAY received; Error code: 11; Debug Text: ping_timeout {grpc_status:14, http2_error:11, created_time:\"2025-05-17T21:27:21.603485805+05:30\"}\n"
     ]
    },
    {
     "ename": "ResponseValidationError",
     "evalue": "The model response did not complete successfully.\nFinish reason: 2.\nFinish message: .\nSafety ratings: [].\nTo protect the integrity of the chat session, the request and response were not added to chat history.\nTo skip the response validation, specify `model.start_chat(response_validation=False)`.\nNote that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseValidationError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      4\u001b[39m test_questions = test_df[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m responses = \u001b[43m[\u001b[49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_questions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m dataset_dict = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: test_questions,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: [response[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses],\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m: [response[\u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses],\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m: test_df[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m].values.tolist(),\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m ragas_eval_dataset = Dataset.from_dict(dataset_dict)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      4\u001b[39m test_questions = test_df[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m responses = [\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_engine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm(test_questions)]\n\u001b[32m      8\u001b[39m dataset_dict = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: test_questions,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: [response[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses],\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m: [response[\u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses],\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m: test_df[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m].values.tolist(),\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m ragas_eval_dataset = Dataset.from_dict(dataset_dict)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mgenerate_response\u001b[39m\u001b[34m(query_engine, question)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_response\u001b[39m(query_engine, question):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: response.response,\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontexts\u001b[39m\u001b[33m\"\u001b[39m: [c.node.get_content() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m response.source_nodes],\n\u001b[32m      6\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py:52\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     51\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m dispatcher.event(\n\u001b[32m     54\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     55\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py:183\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    180\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    181\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m    182\u001b[39m     nodes = \u001b[38;5;28mself\u001b[39m.retrieve(query_bundle)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_response_synthesizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/response_synthesizers/base.py:242\u001b[39m, in \u001b[36mBaseSynthesizer.synthesize\u001b[39m\u001b[34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[39m\n\u001b[32m    236\u001b[39m     query = QueryBundle(query_str=query)\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_manager.event(\n\u001b[32m    239\u001b[39m     CBEventType.SYNTHESIZE,\n\u001b[32m    240\u001b[39m     payload={EventPayload.QUERY_STR: query.query_str},\n\u001b[32m    241\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     response_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMetadataMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     additional_source_nodes = additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    251\u001b[39m     source_nodes = \u001b[38;5;28mlist\u001b[39m(nodes) + \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/response_synthesizers/compact_and_refine.py:43\u001b[39m, in \u001b[36mCompactAndRefine.get_response\u001b[39m\u001b[34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[32m     42\u001b[39m new_texts = \u001b[38;5;28mself\u001b[39m._make_compact_text_chunks(query_str, text_chunks)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py:179\u001b[39m, in \u001b[36mRefine.get_response\u001b[39m\u001b[34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[32m    178\u001b[39m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    183\u001b[39m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[32m    184\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._refine_response_single(\n\u001b[32m    185\u001b[39m             prev_response, query_str, text_chunk, **response_kwargs\n\u001b[32m    186\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py:241\u001b[39m, in \u001b[36mRefine._give_response_single\u001b[39m\u001b[34m(self, query_str, text_chunk, **response_kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._streaming:\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    239\u001b[39m         structured_response = cast(\n\u001b[32m    240\u001b[39m             StructuredRefineResponse,\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    245\u001b[39m         )\n\u001b[32m    246\u001b[39m         query_satisfied = structured_response.query_satisfied\n\u001b[32m    247\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/response_synthesizers/refine.py:85\u001b[39m, in \u001b[36mDefaultRefineProgram.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m     83\u001b[39m         answer = answer.model_dump_json()\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer=answer, query_satisfied=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/llms/llm.py:616\u001b[39m, in \u001b[36mLLM.predict\u001b[39m\u001b[34m(self, prompt, **prompt_args)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata.is_chat_model:\n\u001b[32m    615\u001b[39m     messages = \u001b[38;5;28mself\u001b[39m._get_messages(prompt, **prompt_args)\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    617\u001b[39m     output = chat_response.message.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py:173\u001b[39m, in \u001b[36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[39m\u001b[34m(_self, messages, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    165\u001b[39m     CBEventType.LLM,\n\u001b[32m    166\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m     },\n\u001b[32m    171\u001b[39m )\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     f_return_val = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    175\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    176\u001b[39m         CBEventType.LLM,\n\u001b[32m    177\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    178\u001b[39m         event_id=event_id,\n\u001b[32m    179\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/llms/vertex/base.py:254\u001b[39m, in \u001b[36mVertex.chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mexamples\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m (\n\u001b[32m    249\u001b[39m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    250\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mexamples are not supported in chat generation pass them as a constructor parameter\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    251\u001b[39m         )\n\u001b[32m    252\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m generation = \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_is_gemini\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchat_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m content, tool_calls = \u001b[38;5;28mself\u001b[39m._get_content_and_tool_calls(generation)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ChatResponse(\n\u001b[32m    268\u001b[39m     message=ChatMessage(\n\u001b[32m    269\u001b[39m         role=MessageRole.ASSISTANT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    273\u001b[39m     raw=generation.\u001b[34m__dict__\u001b[39m,\n\u001b[32m    274\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/llms/vertex/utils.py:113\u001b[39m, in \u001b[36mcompletion_with_retry\u001b[39m\u001b[34m(client, prompt, max_retries, chat, stream, is_gemini, params, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    111\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m client.predict(prompt, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/191/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/191/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/llama_index/llms/vertex/utils.py:95\u001b[39m, in \u001b[36mcompletion_with_retry.<locals>._completion_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     tools = to_gemini_tools(tools) \u001b[38;5;28;01mif\u001b[39;00m tools \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m     93\u001b[39m     generation_config = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m chat:\n\u001b[32m    102\u001b[39m     generation = client.start_chat(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1337\u001b[39m, in \u001b[36mChatSession.send_message\u001b[39m\u001b[34m(self, content, generation_config, safety_settings, tools, labels, stream)\u001b[39m\n\u001b[32m   1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_message_streaming(\n\u001b[32m   1330\u001b[39m         content=content,\n\u001b[32m   1331\u001b[39m         generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1334\u001b[39m         labels=labels,\n\u001b[32m   1335\u001b[39m     )\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1475\u001b[39m, in \u001b[36mChatSession._send_message\u001b[39m\u001b[34m(self, content, generation_config, safety_settings, tools, labels)\u001b[39m\n\u001b[32m   1473\u001b[39m \u001b[38;5;66;03m# By default we're not adding incomplete interactions to history.\u001b[39;00m\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_validator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1475\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_response_validator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1479\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1481\u001b[39m \u001b[38;5;66;03m# Adding the request and the first response candidate to history\u001b[39;00m\n\u001b[32m   1482\u001b[39m response_message = response.candidates[\u001b[32m0\u001b[39m].content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Github/rag-ddods-cc/.venv/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1237\u001b[39m, in \u001b[36m_validate_response\u001b[39m\u001b[34m(response, request_contents, response_chunks)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message:\n\u001b[32m   1232\u001b[39m     message += (\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo protect the integrity of the chat session, the request and response were not added to chat history.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo skip the response validation, specify `model.start_chat(response_validation=False)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1235\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1236\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseValidationError(\n\u001b[32m   1238\u001b[39m         message=message,\n\u001b[32m   1239\u001b[39m         request_contents=request_contents,\n\u001b[32m   1240\u001b[39m         responses=response_chunks,\n\u001b[32m   1241\u001b[39m     )\n",
      "\u001b[31mResponseValidationError\u001b[39m: The model response did not complete successfully.\nFinish reason: 2.\nFinish message: .\nSafety ratings: [].\nTo protect the integrity of the chat session, the request and response were not added to chat history.\nTo skip the response validation, specify `model.start_chat(response_validation=False)`.\nNote that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service."
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "test_questions = test_df[\"question\"].values\n",
    "\n",
    "responses = [generate_response(query_engine, q) for q in tqdm(test_questions)]\n",
    "\n",
    "dataset_dict = {\n",
    "    \"question\": test_questions,\n",
    "    \"answer\": [response[\"answer\"] for response in responses],\n",
    "    \"contexts\": [response[\"contexts\"] for response in responses],\n",
    "    \"ground_truth\": test_df[\"ground_truth\"].values.tolist(),\n",
    "}\n",
    "\n",
    "ragas_eval_dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02777779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ac31163",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ragas_eval_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m metrics = [faithfulness, answer_correctness,\n\u001b[32m      2\u001b[39m            context_recall, context_precision]\n\u001b[32m      5\u001b[39m evaluation_result = evaluate(\n\u001b[32m      6\u001b[39m     llm=critic_llm,\n\u001b[32m      7\u001b[39m     embeddings=ollama_emb,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     dataset=\u001b[43mragas_eval_dataset\u001b[49m,\n\u001b[32m      9\u001b[39m     metrics=metrics\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'ragas_eval_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = [faithfulness, answer_correctness,\n",
    "           context_recall, context_precision]\n",
    "\n",
    "\n",
    "evaluation_result = evaluate(\n",
    "    llm=critic_llm,\n",
    "    embeddings=ollama_emb,\n",
    "    dataset=ragas_eval_dataset,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2beedc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
